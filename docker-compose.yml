version: '3.7'

services:
  cheshire-cat-core:
    image: ghcr.io/cheshire-cat-ai/core:1.6.2
    container_name: cheshire_cat_core
    depends_on:
      - cheshire-cat-vector-memory
      - ollama
    environment:
      PYTHONUNBUFFERED: "1"
      WATCHFILES_FORCE_POLLING: "true"
      CORE_HOST: ${CORE_HOST:-localhost}
      CORE_PORT: ${CORE_PORT:-1865}
      QDRANT_HOST: ${QDRANT_HOST:-cheshire_cat_vector_memory}
      QDRANT_PORT: ${QDRANT_PORT:-6333}
      CORE_USE_SECURE_PROTOCOLS: ${CORE_USE_SECURE_PROTOCOLS:-false}
      API_KEY: ${API_KEY:-}
      LOG_LEVEL: ${LOG_LEVEL:-WARNING}
      DEBUG: ${DEBUG:-false}
      SAVE_MEMORY_SNAPSHOTS: ${SAVE_MEMORY_SNAPSHOTS:-false}
    ports:
      - "${CORE_PORT:-1865}:80"
    volumes:
      - ./cat/static:/app/cat/static
      - ./cat/plugins:/app/cat/plugins
      - ./cat/data:/app/cat/data
    restart: unless-stopped

  cheshire-cat-vector-memory:
    image: qdrant/qdrant:v1.9.1
    container_name: cheshire_cat_vector_memory
    environment:
      LOG_LEVEL: ${LOG_LEVEL:-WARNING}
    expose:
      - "6333"
    volumes:
      - ./cat/long_term_memory/vector:/qdrant/storage
    restart: unless-stopped

  ollama:
    image: ollama/ollama:0.1.39
    container_name: ollama_cat
    environment:
      OLLAMA_FLASH_ATTENTION: ${OLLAMA_FLASH_ATTENTION:-false}
      OLLAMA_DEBUG: ${OLLAMA_DEBUG:-false}
      OLLAMA_KEEP_ALIVE: ${OLLAMA_KEEP_ALIVE:-"5m"}
      OLLAMA_MAX_LOADED_MODELS: ${OLLAMA_MAX_LOADED_MODELS:-1}
      OLLAMA_NUM_PARALLEL: ${OLLAMA_NUM_PARALLEL:-1}
    expose:
      - "11434"
    volumes:
      - ./ollama:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
